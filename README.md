# Speech-Emotion-Recognition
This project employs machine learning, specifically the MLPClassifier, to accurately identify emotions in audio files. Drawing on a literature survey, the project builds on previous studies, addressing the challenge of developing a robust model. Leveraging four diverse datasets, the methodology covers data processing, feature extraction, and model training. The model achieves a 65% accuracy in emotion identification, with future work focusing on exploring alternative algorithms and data sources. The project's findings contribute to the field of emotion recognition, with potential applications in mental health and customer service.

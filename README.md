# Speech-Emotion-Recognition
This project employs machine learning, specifically the MLPClassifier, to accurately identify emotions in audio files. Drawing on a literature survey, the project builds on previous studies, addressing the challenge of developing a robust model. Leveraging four diverse datasets, the methodology covers data processing, feature extraction, and model training. The model achieves a 65% accuracy in emotion identification, with future work focusing on exploring alternative algorithms and data sources. The project's findings contribute to the field of emotion recognition, with potential applications in mental health and customer service.
This GitHub repository houses a Speech Emotion Recognition (SER) project employing machine learning, specifically the MLPClassifier, to accurately discern emotions from audio files. The project encompasses data collection, pre-processing, feature extraction, model training, and evaluation. Four diverse datasets, including Ravdess, Crema-D, Savee, and TESS, contribute to the model's development. The trained model achieves a commendable 65% accuracy in emotion identification.

Key Sections:
Overview: Brief explanation of the project's purpose and scope.
Project Structure: Description of the repository's organization, outlining key directories and files.
How to Use: Instructions for cloning the repository, installing dependencies, and utilizing Jupyter Notebooks for various project stages.
Datasets: Details about the datasets used in the project, available in the datasets/ directory.
Results: Highlights the project's achievements, with the trained model reaching a 65% accuracy.
Future Work: Suggestions for future enhancements, including exploring alternative algorithms and datasets.
Contributors: Lists the contributors to the project.
License: Specifies the project's MIT License.
Acknowledgments: Recognizes the project's foundation in existing literature and studies, referenced in the repository.
